{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be851d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dry Bean Dataset CSV file into a Pandas dataframe\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Purvesh\\\\OneDrive\\\\Documents\\\\MACHINE LEARNING\\Dry_Bean_Dataset_11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataset, such as column names, data types, and missing values\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23053528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a heatmap of missing values in the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(dataset.isnull(), cmap='Blues', yticklabels=False)\n",
    "\n",
    "# Adding labels and title and displaying the plot\n",
    "plt.title('Missing Values in Dry Bean Dataset', fontsize=16)\n",
    "plt.xlabel('Columns Names', fontsize=12)\n",
    "plt.ylabel('Distribution', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a6cfa",
   "metadata": {},
   "source": [
    "#### We can interpret from the graph that there are no null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73442037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot of the 'Class' variable using Seaborn\n",
    "sns.countplot(x='Class', data=dataset)\n",
    "\n",
    "# Add title to the countplot\n",
    "plt.title('Count of Classes in the Dataset')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9823df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the dataset using 20 bins and a figure size of 15x15\n",
    "dataset.hist(bins=20, figsize=(15,15))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37f35e",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'Class' variable using LabelEncoder and display the first 200 rows of the dataset\n",
    "labelencoder = LabelEncoder()\n",
    "dataset[\"Class\"] = labelencoder.fit_transform(dataset['Class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633da63",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = dataset.drop(columns='Class') # X contains all columns except 'Class'\n",
    "y = dataset['Class'] # y contains only the 'Class' column\n",
    "\n",
    "# Split the dataset into training and testing sets with a 80:20 ratio and a random state of 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the size of the training set by counting the number of rows in X_train\n",
    "train_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348dfc60",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an Extra Trees classifier model with 500 estimators and a random state of 42\n",
    "model = ExtraTreesClassifier(n_estimators=500, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X,y)\n",
    "\n",
    "# Print the feature importances along with the corresponding column names\n",
    "for feature_name, feature_importance in zip(X.columns, model.feature_importances_):\n",
    "    print(f\"{feature_name}: {feature_importance}\")\n",
    "\n",
    "# Create a Pandas Series containing the feature importances with column names as indices\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort the feature importances in descending order and select the top 10 features\n",
    "feat_importances_sorted = feat_importances.nlargest(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fca614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a horizontal bar plot\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.barplot(x=feat_importances_sorted, y=feat_importances_sorted.index, palette='coolwarm', ax=ax)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "ax.set_title('ExtraTreesClassifier Top 10 Feature Importances')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02b9c3",
   "metadata": {},
   "source": [
    "### Standardized Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd439d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler object and fit it to the training data\n",
    "scaler_X = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the training and testing data using the trained scaler\n",
    "X_train_scaled = scaler_X.transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single function to plot a confusion matrix using scikit-learn's ConfusionMatrixDisplay for different models\n",
    "def plot_confusion_matrix(model, X_test_scaled, y_test, labelencoder):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model (object): The trained classification model to evaluate\n",
    "        X_test_scaled (numpy array): The testing feature matrix (after standardization)\n",
    "        y_test (numpy array): The testing target vector\n",
    "        labelencoder (object): The LabelEncoder object used to encode the target variable\n",
    "    \"\"\"\n",
    "    titles_options = [\n",
    "        (\"Confusion matrix\", None,'.0f')\n",
    "    ]\n",
    "    for title, normalize, values_format in titles_options:\n",
    "        disp = ConfusionMatrixDisplay.from_estimator(\n",
    "            model,\n",
    "            X_test_scaled,\n",
    "            y_test,\n",
    "            display_labels=np.unique(labelencoder.inverse_transform(y)),\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "            xticks_rotation='vertical',\n",
    "            values_format= values_format\n",
    "        )\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c832b8e",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MLPClassifier object with specific hyperparameters\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                          activation='relu', \n",
    "                          solver='adam', \n",
    "                          batch_size=train_size, \n",
    "                          learning_rate='constant', \n",
    "                          learning_rate_init=0.001, \n",
    "                          max_iter=1000, \n",
    "                          random_state=42)\n",
    "\n",
    "# Train the MLPClassifier model using the training data after standardization\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on the testing data using the trained MLPClassifier model\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification accuracy score and error rate for the MLPClassifier model\n",
    "print('Accuracy: %.8f' % accuracy_score(y_test, y_pred_mlp))\n",
    "print('Error Rate', 1 - accuracy_score(y_test, y_pred_mlp))\n",
    "\n",
    "# Print a classification report for the MLPClassifier model\n",
    "# The report includes precision, recall, F1-score, and support for each class label\n",
    "# The target names are inferred from the LabelEncoder object and are displayed in alphabetical order\n",
    "print(classification_report(y_test, y_pred_mlp, target_names=np.unique(labelencoder.inverse_transform(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the MLPClassifier model\n",
    "# The confusion matrix shows the true and predicted class labels for each instance in the testing data\n",
    "# The diagonal of the matrix represents the number of correct predictions for each class label\n",
    "# Off-diagonal entries represent the number of incorrect predictions for each pair of class labels\n",
    "plot_confusion_matrix(mlp_model, X_test_scaled, y_test, labelencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d571694",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune and their possible values\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': randint(10, 101),\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': randint(100, 2001),\n",
    "}\n",
    "\n",
    "# Create an MLPClassifier object with default hyperparameters\n",
    "mlp_model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Perform a randomized search with 5-fold cross-validation using the hyperparameter distribution and the MLPClassifier model\n",
    "random_search = RandomizedSearchCV(mlp_model, param_distributions=param_dist, cv=5)\n",
    "\n",
    "# Fit the randomized search object to the training data after standardization\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding classification accuracy score\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "print(\"Accuracy: %.5f\" % random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abe4f3",
   "metadata": {},
   "source": [
    "### MLP model wtih Hyperparaters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MLPClassifier object with tuned hyperparameters\n",
    "mlp_model_tuned = MLPClassifier(hidden_layer_sizes=(80, ), \n",
    "                          activation='logistic', \n",
    "                          solver='adam', \n",
    "                          learning_rate_init=0.001, \n",
    "                          max_iter=837, \n",
    "                          random_state=42)\n",
    "\n",
    "\n",
    "# Train the MLPClassifier model using the training data after standardization\n",
    "mlp_model_tuned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on the testing data using the trained MLPClassifier model with hyperparameter tuning\n",
    "y_pred_mlp_tuned = mlp_model_tuned.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification accuracy score and error rate for the MLPClassifier model wtih Hyperparaters Tuning\n",
    "print('Accuracy: %.8f' % accuracy_score(y_test, y_pred_mlp_tuned))\n",
    "print('Error Rate', 1 - accuracy_score(y_test, y_pred_mlp_tuned))\n",
    "\n",
    "\n",
    "# Print a classification report for the MLPClassifier model wtih Hyperparaters Tuning\n",
    "# The report includes precision, recall, F1-score, and support for each class label\n",
    "# The target names are inferred from the LabelEncoder object and are displayed in alphabetical order\n",
    "\n",
    "print(classification_report(y_test, y_pred_mlp_tuned, target_names=np.unique(labelencoder.inverse_transform(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the MLPClassifier model with Hyperparaters Tuning\n",
    "# The confusion matrix shows the true and predicted class labels for each instance in the testing data\n",
    "# The diagonal of the matrix represents the number of correct predictions for each class label\n",
    "# Off-diagonal entries represent the number of incorrect predictions for each pair of class labels\n",
    "plot_confusion_matrix(mlp_model_tuned, X_test_scaled, y_test, labelencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc8b3d",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30bd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine model with RBF kernel and specific hyperparameters\n",
    "svm_model = SVC(C=1.0, \n",
    "                kernel='rbf', \n",
    "                degree=3, \n",
    "                gamma='scale', \n",
    "                coef0=0.0, \n",
    "                cache_size=200, \n",
    "                class_weight=None, \n",
    "                max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                random_state=42)\n",
    "# Train the SVM model using the training data after standardization\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on the testing data using the trained SVM model\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy score and error rate of the SVM model on the test data\n",
    "print('Accuracy: %.8f' % accuracy_score(y_test, y_pred_svm))\n",
    "print('Error Rate', 1 - accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Convert the elements in target_names to strings\n",
    "target_names = np.array([str(label) for label in np.unique(labelencoder.inverse_transform(y))])\n",
    "\n",
    "#Prints the classification report for the predicted values of SVM model on the test data, including precision, recall, f1-score, and support for each class.\n",
    "print(classification_report(y_test, y_pred_svm, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the SVM model\n",
    "plot_confusion_matrix(svm_model, X_test_scaled, y_test, labelencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79932935",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_dist = {'C': sp_uniform(loc=0, scale=10),\n",
    "              'gamma': ['scale', 'auto'] + list(sp_uniform(loc=0, scale=1).rvs(5)),\n",
    "              'kernel': ['linear', 'poly', 'rbf'], # removing sigmoid as it is used for binary classification\n",
    "              'degree': sp_randint(1, 6),\n",
    "              'coef0': sp_uniform(loc=0, scale=10)}\n",
    "\n",
    "# Define the model\n",
    "svm = SVC()\n",
    "\n",
    "# Define the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=svm,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to your dataset\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fdfca",
   "metadata": {},
   "source": [
    "### SVM model with Hyperparaters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM model with the best hyperparameters\n",
    "svm_model_tuned = SVC(C=1.9579113478929644,\n",
    "                kernel='rbf',\n",
    "                degree=2,\n",
    "                gamma=0.19561646205339078,\n",
    "                coef0=0.6936130087516545,\n",
    "                cache_size=200,\n",
    "                class_weight=None,\n",
    "                max_iter=-1,\n",
    "                decision_function_shape='ovr',\n",
    "                random_state=42)\n",
    "\n",
    "# Fit the SVM model with Hyperparaters Tuning on the training data\n",
    "svm_model_tuned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the SVM model with Hyperparaters Tuning to predict the labels of the test data\n",
    "y_pred_svm_tuned = svm_model_tuned.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf060bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy score and error rate of the SVM model wtih Hyperparaters Tuning on the test data\n",
    "print('Accuracy: %.8f' % accuracy_score(y_test, y_pred_svm_tuned))\n",
    "print('Error Rate', 1 - accuracy_score(y_test, y_pred_svm_tuned))\n",
    "\n",
    "# Convert the elements in target_names to strings\n",
    "target_names = np.array([str(label) for label in np.unique(labelencoder.inverse_transform(y))])\n",
    "\n",
    "#Prints the classification report for the predicted values of SVM model with Hyperparaters Tuning on the test data, including precision, recall, f1-score, and support for each class.\n",
    "print(classification_report(y_test, y_pred_svm_tuned, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750cc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the SVM model with Hyperparaters Tuning\n",
    "plot_confusion_matrix(svm_model_tuned, X_test_scaled, y_test, labelencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b110b72",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestClassifier object with specific hyperparameters\n",
    "RF_model = RandomForestClassifier(n_estimators=242, \n",
    "                                   random_state=42, \n",
    "                                   max_depth=None, \n",
    "                                   max_features=14, \n",
    "                                   min_samples_leaf=3, \n",
    "                                   min_samples_split=8)\n",
    "\n",
    "# Fit the RF model on the training data\n",
    "RF_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the RF model to predict the labels of the test data\n",
    "y_pred_rf = RF_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy score and error rate of the RF model\n",
    "print('Accuracy: %.8f' % accuracy_score(y_test, y_pred_rf))\n",
    "print('Error Rate', 1 - accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# Convert the elements in target_names to strings\n",
    "target_names_rf = np.array([str(label) for label in np.unique(labelencoder.inverse_transform(y))])\n",
    "\n",
    "#Prints the classification report\n",
    "print(classification_report(y_test, y_pred_rf, target_names=target_names_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18de8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the RF model\n",
    "plot_confusion_matrix(RF_model, X_test_scaled, y_test, labelencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13c903",
   "metadata": {},
   "source": [
    "### Automatic Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce62aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the index values of X_test as instance id's\n",
    "ids = X_test.index.values\n",
    "\n",
    "# Creating a DataFrame with instance IDs and predicted labels\n",
    "df = pd.DataFrame({'instance_id': ids, 'predicted_label': y_pred_svm})\n",
    "\n",
    "# Saving the DataFrame as a CSV file named predicted_labels.csv\n",
    "df.to_csv('260867.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
